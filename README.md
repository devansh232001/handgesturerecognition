# handgesturerecognition
Created a machine learning model that correctly recognised 9 alphabetical letters in American Sign Language (ASL).
Collected 500+ images per alphabet.
Gesture identification improved by 40% after applying colour conversion, noise reduction, Otsu's thresholding, and convex flaw removal.
Modified deep convolution neural networks and extracted features for classifying hands.
The model achieved an overall accuracy of 98.41% and reported 10 fps, thus allowing for real time evaluation.
